// packages/backend/src/services/llm.service.ts

import axios from 'axios';
import logger from '../utils/logger.js';
import { User } from '@prisma/client';

// Ollama API í˜¸ì¶œ ë° ìŠ¤í‚¬ ì¶”ì¶œì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜
export async function extractSkillsFromBio(bio: string): Promise<string[]> {
    const LLM_PORT = 11434;
    const LLM_API_URL = `http://localhost:${LLM_PORT}/api/generate`;
    const MODEL_NAME = 'gemma3:4b'; // 

    // LLMì— ì •í™•í•œ JSON ì‘ë‹µ í˜•ì‹ì„ ìš”êµ¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸
    const prompt = `ë‹¤ìŒ ì‚¬ìš©ìì˜ ìê¸°ì†Œê°œì„œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬, ì–¸ê¸‰ëœ ê¸°ìˆ  ìŠ¤í‚¬ê³¼ í•´ë‹¹ ìŠ¤í‚¬ì— ëŒ€í•œ ìˆ™ë ¨ë„ë¥¼ 1.0(ì´ˆê¸‰)ì—ì„œ 5.0(ì „ë¬¸ê°€) ì‚¬ì´ì˜ ì†Œìˆ˜ì  ê°’ìœ¼ë¡œ í‰ê°€í•˜ê³ , ê²°ê³¼ë¥¼ JSON í˜•ì‹ì˜ ë¬¸ìì—´ ë°°ì—´ë¡œë§Œ ë°˜í™˜í•˜ì‹œì˜¤. ê° ë¬¸ìì—´ì€ 'ìŠ¤í‚¬ëª…:ìˆ™ë ¨ë„' (ì˜ˆ: ['Python:3.5', 'React:4.0']) í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì–¸ê¸‰ëœ ìŠ¤í‚¬ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì‹œì˜¤.

ìê¸°ì†Œê°œì„œ: ${bio}`;

    try {
        const response = await axios.post(LLM_API_URL, {
            model: MODEL_NAME,
            prompt: prompt,
            stream: false,
            format: 'json',
            options: {
                temperature: 0.1,
            }
        });

        // ğŸš¨ [ìˆ˜ì •] ì‘ë‹µ ê°ì²´ë¥¼ 'any'ë¡œ ëª…ì‹œì ìœ¼ë¡œ ìºìŠ¤íŒ…í•˜ì—¬ íƒ€ì… ì˜¤ë¥˜ë¥¼ í•´ê²°í•©ë‹ˆë‹¤.
        const responseData: any = response.data;
        const rawResponse = responseData.response;

        // JSON ë¬¸ìì—´ íŒŒì‹± ë° í´ë¦¬ë‹
        let jsonString = rawResponse.trim();
        if (jsonString.startsWith('"') && jsonString.endsWith('"')) {
            // LLMì´ ë°˜í™˜í•œ JSON ë¬¸ìì—´ì—ì„œ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ìë¥¼ ì œê±°
            jsonString = jsonString.slice(1, -1).replace(/\\n/g, '').replace(/\\"/g, '"');
        }

        const extracted = JSON.parse(jsonString);

        if (Array.isArray(extracted)) {
            logger.info(`LLM ìŠ¤í‚¬ ì¶”ì¶œ ì„±ê³µ (${MODEL_NAME}): ${extracted.join(', ')}`);
            return extracted as string[];
        }

        logger.error('LLM ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: ë°°ì—´ í˜•ì‹ì´ ì•„ë‹˜', { rawResponse });
        return [];

    } catch (error) {
        logger.error(`LLM API í˜¸ì¶œ ì‹¤íŒ¨ ë˜ëŠ” íŒŒì‹± ì˜¤ë¥˜ (${MODEL_NAME}): Request failed with status code ${error.response?.status || 'N/A'}`, error);
        return [];
    }
}